---
title: Point Cloud Compression
date: 2024-02-13 16:03:17 +0900
updated: 2024-02-19 21:51:40 +0900
tags:
  - lidar
  - lab
---

## Point Cloud Compression

PCC 라고 부르기도 한다.

### Reference

https://pcl.readthedocs.io/projects/tutorials/en/latest/compression.html#octree-compression
- [point cloud library tutorial (한글)](https://pcl.gitbook.io/tutorial/part-0/part00-chapter02)

## 논문 조사
### [Real-time Compression of Point Cloud Streams](https://ieeexplore.ieee.org/document/6224647)

#### Introduction

point cloud 의 큰 size 때문에 처리와 변환이 리소스의 상당한 부분을 차지한다. 특히, 원격 데이터 처리 또는 포인트 클라우드의 실시간 전달은 어렵다. 대역폭이 제한된 환경 (온라인 스트리밍이나 저장소) 를 위해 효율적인 압축 해결책을 개발하는 것은 필수가 되어가고 있다.  

깊이 이미지를 만들어내는 센서를 위해, 여러 접근 방식들이 제안되어 오고 있다. 그 중에서 이미지 압축 분야에서 사용되는 이미 존재하는 방법들을 채택하기도 하고, 일관적으로 샘플링되거나 구성된 포인트 클라우드를 위해 특별하게 고안된 자료 구조나 알고리즘을 이용하기도 한다. 그러나 여러 개의 3D 카메라 시스템을 사용하는 경우에서는, 이미지 영역이 겹치는 것은 중복 정보를 야기하게 되어 이를 위해 다른 해결책이 고려되어야만 한다. 예를 들어, 이는 또한 움직이는 환경에 고정된 기울어진 레이저 스캐너에도 적용이 되는데, 이때 단일 프레임이 특정 포인트에서 찍혔을 것이라고 추측할 수 없다. 여기서, 들어오는 포인트들은 일반적으로 종종 사용될 수 있는 센서의 궤적에 대한 정보에 따라 예비 정렬 (prealign) 되어 있다. (또는 다양한 SLAM 변수들을 사용하여 추정될 수 있다.)  

우리는 이러한 문제를 구성되지 않은 (unorganized) 포인트 클라우드, (즉 무작위 순서로 포인트 집합이 저장되어 있는), 로서 데이터를 다룸으로써 접근했고, 스캔에 빠진 곳이 있거나 샘플링 밀도가 불규칙할 수 있다. 이는 우리의 제안된 시스템을 더 넓은 범위의 센서들과 데이터 획득 전략에서 더욱 일반적이고 접근하기 쉽도록 만들어준다.  

압축 알고리즘은 loss-less (원본 데이터에 포함된 모든 정보는 압축된 형식으로 재구축될 수 있음) 와 lossy 로 넓게 구분될 수 있다. 후자의 경우, 세세한 정보는 특정 수준 정도 희생되지만, 상당히 높은 압축률을 얻을 수 있다. 많은 방법들에서 raw 데이터는 본질적으로 

### Emerging MPEG Standards for Point Cloud Compression

#### Introduction

3D 센싱과 캡쳐 기술의 발전은 VR/AR/MR 컨텐츠 창작과 소통뿐 아니라 스마트 시티, 로봇공학과 자동화 주행 분야를 위한 3D 센싱 분야에서의 혁명의 물결을 해방했다. 현재 현실 세계를 디지털 3차원으로 표현할 수 있고 최종 사용자가 자유롭게 디지털 표현을 펼치게 할 수 있는 가상현실 시장인 거대한 인터넷이 존재한다. 측정에 관한 시각 데이터는 3D 장면과 객체들을 그들의 기하학적 성질과 각각의 특징, 어떤 시간적 변화를 모사한다. 그런 데이터는 일반적으로 3D 모델로부터 컴퓨터에 의해 생성되거나, 여러 대의 카메라나 영상 합성, 전용 기하학적 센서를 사용하여 현실 장면을 포착되기도 한다. 그러한 측정과 관련된 데이터를 위한 흔한 표현 방식은 폴리곤 메쉬 (polygon meshes) 나 포인트 클라우드이다. 시간 정보는 각각의 포착된 개체 (2D 비디오의 한 프레임과 유사한) 들의 형태로 포함되어 있거나, 개체의 위치를 시간의 함수로 표현한다. 측정된 비디오는 완전한 3D 장면이나 개체를 묘사하기 때문에, 그러한 데이터는 어떤 관점에서든지 시각화되어야 한다. 그러므로 측정된 비디오는 어떤 AR, VR, MR 애플리케이션을 가능하게 하는 핵심 기술이며, 특히 Six Degrees of Freedom 제공을 위한 보기 기능을 제공한다.  

이전의 기준들에서의 MPEG는 이미 3D 세상의 코딩으로 간주되었지만, 현재 실제 3D 장면들을 코딩으로 표현하기 위한 기술들의 야심찬 로드맵에 최근에 착수했다. 이러한 기술들 중의 하나는 Point Cloud Compression (PCC) 이라고 하며, 2020 초에 ISO 표준으로 제안될 예정이다. 2017 년에 MPEG 는 PCC 에 대한 제안 요청을 발표했으며, 이후 제안된 기술들의 성능을 평가하고 개선하고 있다. 이러한 포인트 클라우드 데이터는 신호 처리와 압축 연구 커뮤니티에 새로운 과제를 제시한다. 측정된 시각 매체들을 위한 이전 압축 해결법은 컴퓨터로 생성된 내용에 초점을 맞추거나 포착된 자연 컨텐츠를 처리할 때 공간 및 시간적 압축 성능이 낮았다. 3D 센서 신호로 포착된 원본을 위해, scene geometry 는 상세 수준에서 확장성이 있고, 압축에 효율적인 표현이 필요하며, photometric 속성은 균일한 유클리드 그리드에서 샘플링되지 않는 새로운 종류의 신호이므로 표현 및 압축을 위한 새로운 샘플링, 필터링, 변환 툴이 필요하다. 최근 Grph Signal Processing (GSP) 에서의 발전은 이를 위한 방대한 집합의 도구들을 제공해왔다. 

#### Point Cloud Data

몰입형 VR/MR 비디오, 자동차/로봇 내비게이션, 의료 영상 등 새롭게 떠오르는 많은 애플리케이션에는 3D 장면/사물 지오메트리 데이터의 캡쳐와 처리가 필요하다. 이 데이터는 가장 원시적인 형태로, 포인트 클라우드라고 하는 점들의 집합으로 구성된다.  

- 특징
포인트 클라우드는 각각의 3D 포인트들의 집합으로 구성되어 있다. 각각의 포인트는, x, y, z 위치를 가질 뿐만 아니라 색깔, 반사도, 표면 법선 등의 다른 많은 속성을 포함할 수 있다. 이는 개별 포인트들간에 지정된 공간 연결이나 순서 관계가 없다.  
특정 컴퓨터 그래픽스와 게임 애플리케이션을 위해, 3D 장면 객체 지오메트리는 일반적으로 일련의 정점들을 서로 연결하는 엣지, 표면의 정보를 통해 구성된 polygonal meshes 로 표현된다. 이러한 polygonal mesh 들은 촘촘한 표면을 간결한 표현하기 위해 잘 짜여져 있지만, 그들은 non-manifold 구조를 표현하는데에 문제가 있다. 포인트 클라우드 표현 방식이 갖는 polygonal mesh 에 비해 가장 큰 장점은 non-manifold 지오메트리를 표현하는 유연성과 저장, 관리하거나 표면 topological 정보를 처리할 필요 없이 실시간 처리가 가능하다는 점이다.  
효율적인 포인트 클라우드 데이터 처리를 위해, 각 포인트는 큐빅 그리드로 quantize 된다. 결과 voxel을 옥트리 데이터 구조에 매핑하여 복셀화된 옥트리를 생성할 수 있으며, 이를 통해 인접한 복셀의 탐색, 검색, 접근이 용이해진다. 

- 사용 예시 & 응용
3D 포인트 클라우드 데이터는 문화 유산/박물관, 3D 무료 비디오, 텔레프레젠스 등 많은 분야에서 적용되고 있다. 문화 유산 분야에서, 포인트 클라우드 데이터는 박물관에 있는 역사적 조각상들이나 건물 같은 것을 포함한 물건들을 보관하고 시각화 하기 위해 사용된다. 이 경우의 일반적인 포인트 클라우드들은 1cm 지오메트릭 정확도와 색깔 컴퓨넌트 정확도 당 8-12 비트를 포함하는 것보다 더 세세한 데이터를 갖는 포인트 클라우드는 수백만에서 수십억의 포인트들을 포함할 수 있다.  
대용량 비디오의 목적은 더 높은 이미지 화질을 뛰어넘고, 더 높은 관점에서의 3D 유저 경험과 상호작용을 제공하기 위함이다. 실시간 3D 텔레프레젠스는 대용량 비디오와 3D 포인트 클라우드의 핵심 애플리케이션 중 하나로, 무작위하고 관련 없는 포인트들의 집합은 시각화, 필터링 및 편집이 간편하기 때문에 선호되는 데이터 표현 형식이다. 3D 텔레프레젠스가 사용되는 몇 가지 예시는 마이크로소프트의 Holoportation 과 8i 의 volumetric 비디오 기술을 포함한다. 대용량 비디오의 변화는 VR 과 3D 스포츠 리플레이와 브로드캐스팅에 기초한 HMD를 포함하는데, 이는 실시간 처리를 요구하지 않거나 추가로 그래픽 데이터 컨텐츠에 기초한 mesh 를 포함할 수도 있다. 그러한 미디어와 관련된 사용 사례는 보통 십만에서 천만 사이의 포인트 위치와 색상 정보, 몇 가지의 시간 정보를 가지며, 비디오 sequence 의 프레임들과 유사하다.  
네비게이션 목적으로는, 높은 밀도의 레이저 스캐너인 LiDAR 로 측정된 깊이 수치와 카메라로 캡쳐된 이미지들, GPS 로 측정된 현지화된 데이터, IMU 데이터를 결합하여 3D 지도를 생성해낼 수 있다. 이러한 지도들은 도시 주위의 자동차들의 자동 길찾기를 가능하게 해주는 레인 정보나 도로 신호 같은 길 신호와 결합될 수도 있다. 이런 사용 예시는 1 cm 정확도까지의 수백만에서 수십억의 3D 포인트 캡쳐와 추가적인 속성을 함께 필요로 한다.이러한 넓은 범위의 애플리케이션에 대응하기 위해, MPEG PCC 표준화 활동은 포인트 클라우드 테스트 데이터의 일반적인 3가지 카테고리 (static, dynamic, dynamically acquired) 들을 생성했다.

- 캡쳐 & 획득
이미 이미지, 비디오, LIDAR 센서 데이터를 압축하기 위한 많은 기준들이 이미 존재한다. 그래서 이 PCC 기준은 raw 센서 데이터를 압축하는 것이 아니라, 센서에 의해 포착된 객체와 장면의 포인트 클라우드 표현을 압축하는 것을 목표로 한다. 여기서 개발된 코딩 기술은 일반적으로 포인트 클라우드 데이터를 생성하는 데 사용하는 특정 센서에 구애받지 않도록 설계되었으므로 압축하기 전에 여러 센서의 3D 데이터를 융합하여 압축할 포인트 클라우드 표현을 생성한다고 가정한다. 모바일 매핑과 자동화된 네비게이션을 위한 동적으로 데이터를 얻는 센서 시스템의 예시는 다음과 같다. LIDAR 센서는 차량의 위에 고정되어 방출된 레이저 빔의 방위와 높이에 기반하여 지속적으로 차량에 상대적인 포인트 위치를 수집한다. GPS 와 관성 센서는 차량의 위치를 파악하는 데 사용된다. LIDAR 가 포착한 상대적인 포인트 위치들과 차량의 위치를 함께 결합함으로써, 포인트 위치들은 고정된 지리 좌표 계에 상대적인 절대적 x, y, z 좌표들로 변환된다. 고정된 RGB 카메라들은 일련의 이미지나 비디오를 캡처한다. 이러한 데이터는 캡쳐 후 처리 작업에서 융합되어 각 포인트가 LIDAR 로 캡쳐한 반사율 속성 외에도 단일 RGB 색상 속성을 가질 수 있도록 한다. 융합 프로세스는 중복되거나 외곽에 있는 지점들을 제거하는 등 데이터를 정리할 수도 있다. 이 과정의 최종 결과는 각 포인트와 관련된 반사율 및 RGB 속성과 함께 (x, y, z) 포인트 좌표 목록으로 구성된 포인트 클라우드이다. 위도, 경도, GPS 타임스탬프와 같은 추가 속성도 속성으로 포함될 수 있지만, 이러한 추가 속성의 압축은 현재 개발 중인 이 표준의 범위를 벗어난다. 

### Comparative Study of 3D Point Cloud Compression Methods

#### Introduction

포인트 클라우드는 대규모의 3D 모델링에서 사용될 수 있는 측정값의 집합이다. 포인트 클라우드들은 지오메트리 정보와 관련 특징, 더하여 시간적 변화를 모두 전달할 수 있다. 포인트 클라우드는 많은 분야에서 광범위하게 사용되고 있는데, VR, AR, 실시간 대규모 통신, 바이오메디컬 이미지, 자율주행 시스템 등이다. 주로 LidAR 센서나 3D 레이저 스캐너, 스테레오 카메라들을 사용하여 포인트 클라우드를 생성한다. 3D 데이터 획득 기술의 최근의 진보는 효율적이고, 정확하고, 신뢰성 있고, 실시간으로 포인트 클라우드 표현을 제공한다. 그러나, 3D 센서로 생성된 포인트 클라우드 데이터의 규모는 거대하다. 예를 들어, 주어진 scene 을 지속적으로 스캐닝하는 64-Line Velodyne LiDAR 센서는 20분 동안 10억개의 포인트를 생성한다; 또한 포인트 초당 30프레임으로 3D 프레임 당 0.7백만 포인트의 클라우드 초당 fps 에 500메가바이트 (MB/s) 정도의 대역폭이 필요하다. 데이터의 거대한 양은 데이터 저장과 전달 모두에 큰 도전 과제를 제기한다. 예를 들어, 포인트 클라우드 데이터를 장치에 지역적으로 저장하는 것은 더 많은 공간을 필요로 하고, 다른 네트워크 노드와 데이터를 공유하거나, 조작하거나, 분석하는 것이 더 어렵다. 최근 몇 년 간, 몇몇의 포인트 클라우드 압축 방법이 개발되어오고 있다. 존재하는 PCC 알고리즘의 성능을 평가하기 위한 노력도 있었지만, 대부분은 데이터 세트와 특정 설정을 가진 소규모 압축 기술 집합에 초점을 맞추고 있다.

#### 3D PCC Methods

G-PCC 는 Apple에서 제안한 지오메트리에 기반한 기술이다. G-PCC 는 옥트리 표현으로 얻어진 좌표들을 사용해서 지오메트리 위치를 직접적으로 3D 공간에 인코딩한다. 지오메트리 위치는 두 가지 방법론을 사용하여 인코드 될 수 있고, 포인트 클라우드의 속성은 3개의 다른 방법을 사용하여 인코딩 될 수 있다. 마지막 비트스트림은 지오메트리 비트스트림과 색상 비트스트림 모두로부터 생산될 수 있다. 
V-PCC 는 투사에 기반한 코딩 원리를 채택했고, 마찬가지로 Apple 에서 제안되었다. V-PCC 는 포인트 클라우드 데이터를 patch 들의 집합으로 해체한다. 3D 패치는 여러 직교 방향에서 생성되어 2D 평면에 투영된다. 이러한 2D 패치들은 2D 비디오 인코더 기술을 사용하여 처리될 수 있다. 결과 투사 이미지에 깊이와 속성 정보를 모두 유지할 수 있다. 
Draco 는 구글에 의해 개발된 3D 지오메트리 메쉬와 포인트 클라우드들을 압축하고, 압축해제하는 오픈소스 라이브러리이다. Draco 의 주된 아이디어는 KD 트리를 사용하는 것이다. KD 트리 형성 후, Draco 는 데이터를 엔트로피 인코딩 툴을 사용하여 인코딩한다. 유저의 필요에 따라 압축된 파일 크기와 포인트 클라우드의 시각적 질 사이의 트레이드 오프가 있다. 
GeoCNNv2 는 GeoCNNv1 에서 향상된 아키텍쳐이다. GeoCNNv1 아키텍쳐는 3 계층의 분석 변환과 균일한 양자화 모듈, 3계층의 합성 변환으로 구성된 3D 컨볼루션 자동 인코더(CNN-AE) 이다. GeoCNNV2는 GeoCNNv1 을 기본 모델로 사용한 다음 엔트로피 모델링, 심층 변환, 초점 손실의 균형 가중치 변경, 디코딩의 최적 임계값, 순차적 훈련 등 몇 가지 새로운 구현을 추가했다. 